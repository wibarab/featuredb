{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script to automate the export and manipulation of the VICAV-library\n",
    "\n",
    "## Import Package eTree to parse XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import isoschematron, etree\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import asyncio\n",
    "import aiohttp\n",
    "# this module is needed to make asyncio.run work inside the notebook as well as in the generated python script\n",
    "import nest_asyncio\n",
    "from random import random\n",
    "import saxonche\n",
    "import itertools \n",
    "from datetime import datetime\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define name-space for xml-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmlns = {\"tei\": \"http://www.tei-c.org/ns/1.0\", \"xml\":\"http://www.w3.org/XML/1998/namespace\", \"\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "for key in xmlns:\n",
    "    ET.register_namespace(key, xmlns[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access to the VICAV Zotero library\n",
    "\n",
    "* Use API_TOKEN from environment to access Zotero\n",
    "* Set the Zotero group id for VICAV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_headers = {'Authorization': 'Bearer ' + os.environ['API_TOKEN']}\n",
    "group_id = \"2165756\"\n",
    "limit_downloads_to = int(os.environ['LIMIT_DOWNLOADS_TO']) if 'LIMIT_DOWNLOADS_TO' in os.environ and os.environ['LIMIT_DOWNLOADS_TO'] else None\n",
    "# On GitHub more than one connections to api.zotero.org was broken when this environment variable was introduced\n",
    "conn_limit=int(os.environ['MAX_CONNECTIONS']) if 'MAX_CONNECTIONS' in os.environ and os.environ['MAX_CONNECTIONS'] else 4 \n",
    "total_timeout=int(os.environ['TIMEOUT']) if 'TIMEOUT' in os.environ and os.environ['TIMEOUT'] else 5 #s\n",
    "logging.info(\"limit_downloads_to = \" + str(limit_downloads_to) + \", conn_limit = \" + str(conn_limit) + ', total_timeout = ' + str(total_timeout) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Read all items in the library\n",
    "\n",
    "Load items from Zotero group library\n",
    "\n",
    "    Args: \n",
    "        group_id (str): ID of a Zotero group\n",
    "        limit (int): number of items to retrieve from library, maximum is 100.\n",
    "        start (int): item number to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_items(session, group_id:str,limit:int,start:int,itemType = None,format = None):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + \"?limit=\" + str(limit) + \"&start=\" + str(start) + (\"&itemType=\"+itemType if itemType is not None else \"\") + (\"&format=\"+format if format is not None else \"\")\n",
    "    retries = 2\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            async with session.get(url=request_url, headers=request_headers) as response:\n",
    "                if response.status == 200:\n",
    "                    if format == \"tei\":\n",
    "                        parsed = ET.fromstring(await response.read())\n",
    "                    else:\n",
    "                        parsed = json.loads(await response.text())\n",
    "                    response_headers = response.headers\n",
    "                    logging.info(\"Got \"+request_url + (\" Backoff: \" + response.headers[\"Backoff\"] if \"Backoff\" in response.headers else \"\"))\n",
    "                    return parsed, response_headers\n",
    "        except Exception as e:\n",
    "            retries = retries - 1\n",
    "            await asyncio.sleep(3 + random() + 0.5)\n",
    "            logging.info(\"Retrying after \" + type(e).__name__ + (\": \" + str(e) if str(e) else \"\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "async def test1():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout) # 10 min\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test1, test_reponse_headers = await get_items(session, group_id,10,1000)\n",
    "        test1a, test_reponse_headersa = await get_items(session, group_id,10,300,\"note\")\n",
    "        print(test_reponse_headers, '\\n', test_reponse_headersa, '\\n', len(test1), ' ', len(test1a), '\\n', test1)\n",
    "asyncio.run(test1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get total number of items in group library\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group\n",
    "    \n",
    "    Returns:\n",
    "        int: number of items in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def total_number_items(group_id) -> int:\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return int(response.headers[\"Total-Results\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "test2 = total_number_items(group_id)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get headers of Zotero-Api-Calls\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_headers(group_id):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return response.headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "test3 = get_headers(group_id)\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get links from headers\n",
    "\n",
    "    Args:\n",
    "        headers: http-headers of a response\n",
    "\n",
    "    Returns:\n",
    "        dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links_from_headers(headers) -> dict:\n",
    "    link_list = headers[\"Link\"].split(\",\")\n",
    "    links = {}\n",
    "    for link_item in link_list:\n",
    "        #print(link_item)\n",
    "        link_type = link_item.split('; rel=\"')[1].replace('\"','').strip()\n",
    "        link_value = link_item.split('; rel=\"')[0].replace(\"<\",\"\").replace(\">\",\"\").strip()\n",
    "        links[link_type] = link_value\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "test_headers = get_headers(group_id)\n",
    "test4 = get_links_from_headers(test_headers)\n",
    "print(test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Get all items of a collection/group lib\n",
    "\n",
    "* Generate all links with `for start in range(limit,last,limit)`.\n",
    "* Then download in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def fetch(request_url, session, format = None):\n",
    "    await asyncio.sleep(1 * random() + 0.5)\n",
    "    retries = 2\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            async with session.get(request_url, headers=request_headers) as response:\n",
    "                if format == \"tei\":\n",
    "                    content = ET.fromstring(await response.read())\n",
    "                else:\n",
    "                    content = json.loads(await response.text())\n",
    "                logging.info(\"Got \"+request_url + (\" Backoff: \" + response.headers[\"Backoff\"] if \"Backoff\" in response.headers else \"\"))\n",
    "                return {\"status\": response.status, \"data\": content}\n",
    "        except Exception as e:\n",
    "            retries = retries - 1\n",
    "            await asyncio.sleep(3 + random() + 0.5)\n",
    "            logging.info(\"Retrying after \" + type(e).__name__ + (\": \" + str(e) if str(e) else \"\"))\n",
    "\n",
    "async def fetch_batch(url_list, format = None):\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        responses = await asyncio.gather(*[fetch(url, session, format) for url in url_list])\n",
    "    return responses\n",
    "\n",
    "async def get_all_items(session, group_id, itemType = None, format = None):\n",
    "    logging.info(\"Getting all items\" + \n",
    "                 ((\" of type \" + itemType) if itemType is not None else \"\") + \n",
    "                 ((\" formatted as \" + format) if format is not None else \"\") + \" now.\")\n",
    "\n",
    "    # settings to be used in the function to get the items (limit is max 100 per single request)\n",
    "    limit=100\n",
    "    start=0\n",
    "    urls = []\n",
    "    \n",
    "    # get the first 200 items to start with\n",
    "    first_round=await get_items(session, group_id,limit,start,itemType,format)\n",
    "    allitems = first_round[0]\n",
    "    \n",
    "    # get the next link from the headers\n",
    "    next_url = get_links_from_headers(first_round[1])[\"next\"]\n",
    "    last_url = get_links_from_headers(first_round[1])[\"last\"]\n",
    "    next_url_parsed = urlparse(next_url)\n",
    "    parsed_qs = parse_qs(next_url_parsed.query)\n",
    "    last_qs = parse_qs(urlparse(last_url).query)\n",
    "    last_start = limit_downloads_to if limit_downloads_to is not None and format is not None else int(last_qs[\"start\"][0])\n",
    "    for start in range(limit, last_start+1, limit):\n",
    "        parsed_qs[\"start\"] = [start]\n",
    "        parsed = next_url_parsed._replace(query=urlencode(parsed_qs, doseq=True))\n",
    "        urls.append(parsed.geturl())\n",
    "    i = 0\n",
    "    while len(urls[i:i+conn_limit]) > 0:\n",
    "        for response in await fetch_batch(urls[i:i+conn_limit], format):\n",
    "            if isinstance(allitems, ET.Element) and isinstance(response[\"data\"], ET.Element):\n",
    "                for child in response[\"data\"]:\n",
    "                    allitems.append(child)\n",
    "            else:\n",
    "                allitems = allitems + response[\"data\"]   \n",
    "        i = i + conn_limit\n",
    "    \n",
    "    return allitems"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "async def test5():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test5 = await get_all_items(session, group_id)\n",
    "        print(test5)\n",
    "asyncio.run(test5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all items of a group library in a json file\n",
    "\n",
    "    Args:\n",
    "        group_id (str): ID of a Zotero group\n",
    "        filename (str): name of the export file including file-extension\n",
    "\n",
    "    Returns:\n",
    "        bool: True if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_all_items_to_file(group_id,filename) ->bool: \n",
    "    allitems = get_all_items(group_id)\n",
    "    with open(filename,\"w\") as f:\n",
    "        json.dump(allitems, f)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#export_all_items_to_file(group_id,\"export_grouplib.json\")\n",
    "with open(\"export_grouplib.json\",\"w\") as f:\n",
    "    json.dump(test5, f)\n",
    "all_items = test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store export in a file and get all item ids\n",
    "\n",
    "The export contains also the note items. These are child items of some other item in this export. They have a parent reference.\n",
    "\n",
    "There are also attachment items. These are child items of some other item in this export. Most of them have a parent reference but some don't have a parent item (anymore?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file = \"export_grouplib.json\"\n",
    "item_ids = []\n",
    "note_ids = []\n",
    "attachment_ids = []\n",
    "async def get_generic_items(session):\n",
    "    if os.path.isfile(json_file):\n",
    "        logging.info(\"Grouplib export json already exists. Delete to fetch again (time consuming).\")\n",
    "        with open(json_file, 'r') as f:\n",
    "            all_items = json.load(f)    \n",
    "    else:\n",
    "        all_items = await get_all_items(session, group_id)\n",
    "    return all_items\n",
    "\n",
    "async def get_export_json():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_generic_items(session)\n",
    "    # all_items = test5\n",
    "    with open(json_file,\"w\") as f:\n",
    "        json.dump(all_items, f)\n",
    "        logging.info(\"Exported json.\")\n",
    "    \n",
    "    for item in all_items:\n",
    "        item_id = item[\"key\"]\n",
    "        item_type = item[\"data\"][\"itemType\"]\n",
    "        if item_type == 'note':\n",
    "            note_ids.append(item_id)\n",
    "        elif item_type == 'attachment':\n",
    "            attachment_ids.append(item_id)\n",
    "        else:\n",
    "            item_ids.append(item_id)\n",
    "    return all_items\n",
    "all_items = asyncio.run(get_export_json())\n",
    "all_items_map = {data[\"key\"]:data for data in all_items}\n",
    "all_notes_map = {data[\"data\"][\"parentItem\"]:data for data in [all_items_map[id] for id in note_ids]}\n",
    "all_attachments_map = {data[\"data\"][\"parentItem\"] if \"parentItem\" in data[\"data\"] else \"ZZZZZZZZ\":data for data in [all_items_map[id] for id in attachment_ids]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "print(len(all_items), ' ', len(note_ids), ' ', len(item_ids), '\\n', item_ids[:10],\n",
    "      '\\nBibl items:\\n', dict(list(all_items_map.items())[:10]),\n",
    "      '\\nNote items:\\n', dict(list(all_notes_map.items())[:10]),\n",
    "      '\\nAttachement items:\\n', dict(list(all_attachments_map.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace xml:id with biblid from extra-field\n",
    "\n",
    "Most (but currently not all) Zotero items should have a canonical biblid assigned. This function gets the value from data/extra and \n",
    "tries to extract the canonical biblid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_xml_id(id):\n",
    "    # https://stackoverflow.com/questions/55038323/how-to-write-a-regex-expression-to-check-a-valid-xml-element-ncname-in-javascrip\n",
    "    p = re.compile(r\"^[a-zA-Z_][\\w.-]*$\")\n",
    "    matches = p.match(id)\n",
    "    if matches:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "malformedBiblIDs=[]\n",
    "def get_biblid_from_extra(item):\n",
    "    if \"extra\" in item[\"data\"]:\n",
    "        if item[\"data\"][\"extra\"] != \"\":\n",
    "            if \"(biblid:\" in item[\"data\"][\"extra\"]:\n",
    "                biblid=item[\"data\"][\"extra\"].split(\":\")[1].replace(\")\",\"\")\n",
    "                if is_valid_xml_id(biblid):\n",
    "                    return biblid\n",
    "                else:\n",
    "                    msg=item[\"key\"] + \" malformed biblid: \" + item[\"data\"][\"extra\"]\n",
    "                    logging.info(msg)\n",
    "                    malformedBiblIDs.append(msg)\n",
    "                    return None\n",
    "                    \n",
    "            else:\n",
    "                msg=item[\"key\"] + \" malformed biblid: \" + item[\"data\"][\"extra\"]\n",
    "                logging.info(msg)\n",
    "                malformedBiblIDs.append(msg)\n",
    "                return None\n",
    "        else:\n",
    "            msg=item[\"key\"] + \" no biblid\"\n",
    "            logging.info(msg)\n",
    "            malformedBiblIDs.append(msg)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "get_biblid_from_extra(all_items[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "for item in all_items[0:20]:\n",
    "    print(get_biblid_from_extra(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biblid_by_zuid={item[\"key\"]: get_biblid_from_extra(item)\n",
    "               for item in all_items}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "biblid_by_zuid[\"D25ZTU9X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the geo data and replace tags with geo refs\n",
    "\n",
    "geo data is in `../../vicav_biblio/vicav_geodata.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_data = ET.parse(\"../../010_manannot/vicav_geodata.xml\")\n",
    "geo_parent_map = {c:p for p in geo_data.iter( ) for c in p}\n",
    "place_by_name = {placeName.text: \n",
    "                 {\"type\": geo_parent_map[placeName].get(\"type\"),\n",
    "                  \"geo\": geo_parent_map[placeName].find(\"./tei:location/tei:geo[@decls='#dd']\",xmlns).text,\n",
    "                  \"el\": geo_parent_map[placeName]}\n",
    "                for placeName in geo_data.findall(\".//tei:listPlace/tei:place/tei:placeName\", xmlns)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#place_by_name = {}\n",
    "#p=1\n",
    "#for placeName in geo_data.findall(\".//tei:listPlace/tei:place/tei:placeName\", xmlns):\n",
    "#    p=p+1\n",
    "#    try:\n",
    "#        place_by_name = {**place_by_name, **{placeName.text: {\"type\": geo_parent_map[placeName].get(\"type\"),\n",
    "#                                                              \"geo\": geo_parent_map[placeName].find(\"./tei:location/tei:geo[@decls='#dd']\",xmlns).text,\n",
    "#                                                              \"el\": geo_parent_map[placeName]}}}\n",
    "#    except AttributeError:\n",
    "#        logging.info(\"Pos \"+str(p)+\" :\"+str(ET.tostring(geo_parent_map[placeName])))\n",
    "\n",
    "print(geo_data.find(\".//tei:listPlace\", xmlns)[1].attrib[\"{http://www.w3.org/XML/1998/namespace}id\"], '\\n',\n",
    "    dict(list(place_by_name.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the current mapping for @n to Zoteros unique ID\n",
    "\n",
    "Zotero suggests readable @xml:id, we use them for @n, but those are not unique between runs or  \n",
    "take into account that there may be more than one works by one author in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_zotero_unique_id = re.compile(r'https?://zotero.org/groups/[\\d]+/items/(?P<zuid>[A-Z0-9]+)')\n",
    "current_bibl_data = ET.parse(\"../../010_manannot/vicav_biblio_tei_zotero.xml\")\n",
    "n_by_zuid = {get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"n\")\n",
    "                 for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns)}\n",
    "zuid_by_n = {bibStr.get(\"n\"): get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]\n",
    "                 for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns)}\n",
    "duplicate_xmlid = {}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "n_by_zuid = {}\n",
    "for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns):\n",
    "    try:\n",
    "        n_by_zuid = {**n_by_zuid,\n",
    "                         **{get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"n\")}\n",
    "                        }\n",
    "    except AttributeError:\n",
    "        logging.info(ET.tostring(bibStr))\n",
    "m = get_zotero_unique_id.match(\"http://zotero.org/groups/2165756/items/5XHDCICS\")\n",
    "m.groupdict()\n",
    "n_by_zuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Get all TEIs from Zotero\n",
    "\n",
    "man nimmt die Liste mit den IDs der entries, baut für jeden entry die URL nach dem Muster  \n",
    "https://api.zotero.org/groups/2165756/items/944KQVKQ?format=tei  \n",
    "man lädt das mit GET requesst  \n",
    "dann aus dem response den body und parsed das mit ET from string, nimmt daraus das  \n",
    "`<biblStruct>` Element;  \n",
    "baut eine gemeinsame `<listBibl>` und fügt das geparste Element ein,  \n",
    "dann dumpt man den ganzen Element-Tree\n",
    "\n",
    "### Retrieves TEI of an item generated by Zotero\n",
    "\n",
    "Resolves place names to geo coordinates using the place by name dict created above.\n",
    "\n",
    "### Keeping the xml:ids stable\n",
    "\n",
    "The code uses the Zotero unique ids to look up the @xml:id in the current bibliography and change it to that if it is needed.  \n",
    "Additionally if the id of the entry just downloaded does not match the known Zotero unique id a new unique @xml:id is generated appending b-z.  \n",
    "This code is not tested very much for corner cases. It should be replaced by getting the canonical biblid from the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "tag_parser = re.compile(r'(?P<geo_type>[^:]+):(?P<geo_name>[^[]+)(\\[(?P<long>[\\d.,]+) +(?P<lat>[\\d.,]+)])?')\n",
    "\n",
    "def create_geo_tag(tags_el, tag):\n",
    "    #starts with reg: geo: diaGroup: -> lookup, get geo location and create elemnt\n",
    "    # uses PEP 634, requires python 3.10+\n",
    "    m = tag_parser.match(tag)\n",
    "    if m is not None:\n",
    "        match m.groupdict():\n",
    "            case {\"geo_type\": \"reg\" | \"geo\" | \"diaGroup\", \"geo_name\": geo_name, \"long\": long, \"lat\": lat}:\n",
    "                tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "                geo_name = geo_name.rstrip()\n",
    "                ET.SubElement(tag_note_el, \"name\", type=m.groupdict()[\"geo_type\"]).text = geo_name\n",
    "                if geo_name in place_by_name:\n",
    "                    ET.SubElement(tag_note_el, \"geo\").text = place_by_name[geo_name][\"geo\"]\n",
    "                else:\n",
    "                    ET.SubElement(tag_note_el, \"note\", type=\"missing_geo_data\")\n",
    "                return tag_note_el\n",
    "    if tag in place_by_name:\n",
    "        tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\", subtype=\"unmarked_geo\")\n",
    "        ET.SubElement(tag_note_el, \"name\", type=place_by_name[tag][\"type\"]).text = tag\n",
    "        ET.SubElement(tag_note_el, \"geo\").text = place_by_name[tag][\"geo\"]\n",
    "        return tag_note_el\n",
    "    ret = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "    ret.text = tag\n",
    "    return ret\n",
    "\n",
    "def extend_item_tei(bibl):\n",
    "    try:\n",
    "        zuid = get_zotero_unique_id.match(bibl.get(\"corresp\")).groupdict()[\"zuid\"]\n",
    "        logging.debug(\"Zoterio unique ID: \" + zuid)\n",
    "        zotero_xmlid = bibl.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "        logging.debug(\"zotero @xml:id: \" + zotero_xmlid)        \n",
    "        bibl.set(\"n\", zotero_xmlid)\n",
    "        if zuid in n_by_zuid and zotero_xmlid != n_by_zuid[zuid]:\n",
    "            bibl.set(\"n\", n_by_zuid[zuid])\n",
    "            logging.info(\"Changed @n for item \" + zuid + \" from \"+ zotero_xmlid + \" to \" + n_by_zuid[zuid] + \".\")\n",
    "        elif zotero_xmlid in zuid_by_n and zuid_by_n[zotero_xmlid] != zuid:\n",
    "            initial_xmlid = zotero_xmlid\n",
    "            if not zotero_xmlid in duplicate_xmlid:\n",
    "                duplicate_xmlid[zotero_xmlid] = zotero_xmlid + \"b\"\n",
    "            else:\n",
    "                duplicate_xmlid[zotero_xmlid] = duplicate_xmlid[zotero_xmlid][:-1] + chr(ord(duplicate_xmlid[zotero_xmlid][-1]) + 1)\n",
    "            zotero_xmlid = duplicate_xmlid[zotero_xmlid]\n",
    "            if zotero_xmlid in zuid_by_n and zuid_by_n[zotero_xmlid] != zuid:\n",
    "                logging.error(\"genereated @n for item \" + zuid + \" is in use!\")\n",
    "            bibl.set(\"n\", zotero_xmlid)            \n",
    "            logging.info(\"Changed @n for item \" + zuid + \" from \"+ initial_xmlid +\n",
    "                         \" to \" + zotero_xmlid + \" (duplicate of \" + zuid_by_n[initial_xmlid] + \")\")\n",
    "        if zuid in biblid_by_zuid and biblid_by_zuid[zuid] is not None:\n",
    "            bibl.set(\"{http://www.w3.org/XML/1998/namespace}id\", biblid_by_zuid[zuid])\n",
    "        if zuid in all_notes_map:\n",
    "            note_for_zuid = all_notes_map[zuid][\"data\"][\"note\"].replace(\"&\", \"&amp;\")\n",
    "            parsed_note = ET.fromstring(\"<note>\"+note_for_zuid+\"</note>\")\n",
    "            bibl.append(parsed_note)\n",
    "        \n",
    "        tags = all_items_map[zuid][\"data\"][\"tags\"]\n",
    "        if len(tags) > 0:\n",
    "            tags_el = ET.SubElement(bibl, \"note\", type=\"tags\")\n",
    "            for o in tags:\n",
    "                create_geo_tag(tags_el, o[\"tag\"])\n",
    "        \n",
    "        meeting_name = all_items_map[zuid][\"data\"].get(\"meetingName\")\n",
    "        if meeting_name is not None:\n",
    "            meeting_el = ET.Element(\"meeting\")\n",
    "            meeting_el.text = meeting_name\n",
    "            monogr_el = bibl.find(\"tei:monogr\",xmlns)\n",
    "            monogr_el.insert(0,meeting_el)\n",
    "\n",
    "        abstract = all_items_map[zuid][\"data\"].get(\"abstractNote\")\n",
    "        if abstract is not None and abstract != \"\":\n",
    "            abstract_el = ET.SubElement(bibl, \"note\", type=\"abstract\")\n",
    "            abstract_el.text = abstract\n",
    "\n",
    "    except xml.etree.ElementTree.ParseError:\n",
    "        logging.info(\"XML parser error in notes for item id \"+zuid+\"\\n\"+note_for_zuid)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + zuid)\n",
    "    logging.debug(\"Extended TEI for \" + zuid)\n",
    "\n",
    "async def get_item_tei(group_id,item_id,session):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + item_id + \"?format=tei\"\n",
    "    bibl = None\n",
    "    note_for_item_id = \"\"\n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        async with session.get(url=request_url, headers=request_headers) as response:\n",
    "            response_text = await response.text()\n",
    "        list_bibl = ET.fromstring(response_text)\n",
    "        bibl = list_bibl.find(\"tei:biblStruct\",xmlns)\n",
    "        logging.debug(\"XML: \" + ET.tostring(bibl, encoding=\"unicode\"))\n",
    "        if bibl is None:\n",
    "            logging.info(\"There is no biblStruct in the response for item \" + item_id +\":\\n\"+response_text)\n",
    "            return bibl\n",
    "        extend_item_tei(bibl)\n",
    "    except asyncio.TimeoutError:\n",
    "        logging.info(\"Timeout fetching \" + item_id)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + item_id)\n",
    "    logging.info(\"Fetched TEI for \" + item_id)\n",
    "    return bibl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_item_tei_test():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        #test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "        #test = await get_item_tei(group_id,\"DXNCFAMR\",session)\n",
    "        #test = await get_item_tei(group_id,\"6QNLQCG9\",session)\n",
    "        #test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "        #test = await get_item_tei(group_id,\"6BGIGGVN\",session)\n",
    "        test = await get_item_tei(group_id,\"3BUJBNPK\",session)\n",
    "    ET.indent(test)\n",
    "    ET.dump(test)\n",
    "asyncio.run(get_item_tei_test())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(\"Notes:\\n\", all_notes_map[\"944KQVKQ\"][\"data\"][\"note\"], \"\\nTags:\\n\", all_items_map[\"944KQVKQ\"][\"data\"][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = ET.parse(\"listbibl_template.xml\")\n",
    "sourceDesc = template.find(\".//tei:sourceDesc/tei:p\", xmlns)\n",
    "now=datetime.now()\n",
    "dateTimeString=\"{:%Y-%m-%d %H:%M:%S}\".format(now)\n",
    "sourceDesc.text = sourceDesc.text.replace(\"{dateTime}\", dateTimeString)\n",
    "list_bibl = template.find(\"tei:text/tei:body/tei:listBibl\",xmlns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load template containing a listBibl-element that will be filled with the retrieved biblStruct elements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "ET.dump(list_bibl)\n",
    "list_bibl.append(test)\n",
    "ET.dump(list_bibl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the TEI\n",
    "\n",
    "* For each item-id get the TEI and append it to list-bibl\n",
    "* Save the resulting XML\n",
    "* Use the same method as for the JSON for the whole group lib\n",
    "* Then download in parallel.\n",
    "\n",
    "We need to consider https://www.zotero.org/support/dev/web_api/v3/basics#rate_limiting\n",
    "\n",
    "TODO: Maybe only get the all the top items in the group with https://api.zotero.org/groups/2165756/items/top?format=tei&limit=100&sort=creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def async_download():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_all_items(session, group_id, format = \"tei\")\n",
    "    return all_items\n",
    "\n",
    "all_items = asyncio.run(async_download())\n",
    "for bibl in all_items:\n",
    "    extend_item_tei(bibl)\n",
    "all_items[:] = sorted(all_items, key=lambda child: child.get(\"{http://www.w3.org/XML/1998/namespace}id\"))\n",
    "for item in all_items:\n",
    "    list_bibl.append(item)\n",
    "\n",
    "pathToZoteroExport='../../010_manannot/vicav_biblio_tei_zotero.xml'\n",
    "with open(pathToZoteroExport, 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8',xml_declaration=True)\n",
    "    logging.info(\"TEI export done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix TEI export\n",
    "\n",
    "Zotero's TEI serialization has some structural errors (elements in wrong position etc.) which we fix witha small XSLT transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "# SaxonC 1.2.1 Python has many known bugs but isn't maintained anymore\n",
    "# Many of the documented API specs are not working\n",
    "    print(proc.version)\n",
    "    proc.set_cwd(os.path.dirname(os.path.abspath('')))\n",
    "    print(proc.cwd)\n",
    "\n",
    "def transform(source, xsl, output, parameters=[]):\n",
    "    try:\n",
    "        with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "            proc.set_configuration_property(\"xi\", \"on\")\n",
    "            saxon = proc.new_xslt30_processor()\n",
    "            for param in parameters:\n",
    "                saxon.set_parameter(name=param, value=proc.make_string_value(parameters[param]))\n",
    "            exec = saxon.compile_stylesheet(stylesheet_file=os.path.abspath(xsl))\n",
    "            exec.apply_templates_returning_file(source_file=os.path.abspath(source), output_file=os.path.abspath(output))\n",
    "            if exec.exception_occurred:\n",
    "                print(saxon.get_error_message())\n",
    "                print(f\"Transformation failed: {source} with stylesheet {xsl} -> {output}\")\n",
    "            if os.path.exists(os.path.abspath(output)):\n",
    "                return output\n",
    "            else:\n",
    "                print(f\"Error transforming {source} with stylesheet {xsl}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def applyTransformation(pathToZoteroExport, xslPath, pathToOutput=None):\n",
    "    if pathToOutput is None:\n",
    "        pathToOutput = pathToZoteroExport + \".tmp\"\n",
    "    transform(pathToZoteroExport, xslPath, pathToOutput)\n",
    "    return pathToOutput\n",
    "\n",
    "# fix Zotero export\n",
    "pathToFixZoteroXSL=\"../../082_scripts_xsl/fix_zotero_TEI_export.xsl\"\n",
    "applyTransformation(pathToZoteroExport, pathToFixZoteroXSL, pathToZoteroExport)\n",
    "\n",
    "# add decade of data collection\n",
    "pathToDOCXSL = \"../../082_scripts_xsl/tei_2_tei_zotero_doc.xsl\"\n",
    "applyTransformation(pathToZoteroExport, pathToDOCXSL, pathToZoteroExport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(path, rngSchema):\n",
    "    \"\"\"Validate a document against the rngSchema. Returns a list of dicts of which each one represents a validation (or parsing) error.\"\"\"\n",
    "    validationErrors = []\n",
    "    \n",
    "    try:\n",
    "        doc = etree.parse(path)\n",
    "    \n",
    "        # relaxng validation\n",
    "        relaxng_doc = etree.parse(rngSchema)\n",
    "        relaxng = etree.RelaxNG(relaxng_doc)\n",
    "        relaxng.assertValid(doc)\n",
    "        \n",
    "    \n",
    "    except etree.XMLSyntaxError as e:\n",
    "        valErrObj = {\n",
    "            \"type\" : \"error\",\n",
    "            \"message\": str(e), \n",
    "            \"line\": e.lineno,\n",
    "            \"source\": path, \n",
    "            \"location\": \"n/a\",\n",
    "            \"stage\" : \"parsing\", \n",
    "            \"exceptionType\": type(e).__name__\n",
    "        }\n",
    "        \n",
    "        validationErrors.append(valErrObj)     \n",
    "        return validationErrors\n",
    "        \n",
    "    except etree.DocumentInvalid as e:\n",
    "        for error in e.error_log:\n",
    "            # we ignore rng errors about @schemaLocation since \n",
    "            # that is needed for validation in the TEI-enricher\n",
    "            if error.message != \"Invalid attribute schemaLocation for element TEI\":\n",
    "                location = \"n/a\" if error.path is None else error.path\n",
    "                valErrObj = {\n",
    "                    \"type\" : \"error\",\n",
    "                    \"message\": error.message, \n",
    "                    \"line\": error.line, \n",
    "                    \"source\": path, \n",
    "                    \"location\": location,\n",
    "                    \"stage\" : \"relaxng\", \n",
    "                    \"exceptionType\": type(e).__name__\n",
    "                }\n",
    "                # DEBUG\n",
    "                print(valErrObj)\n",
    "                validationErrors.append(valErrObj)        \n",
    "    \n",
    "    return validationErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## report duplicate xml:ids\n",
    "\n",
    "Since bibl-ids are entered manually, they might contain duplicate. We report them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoteroExport = ET.parse(pathToZoteroExport)\n",
    "ids=[]\n",
    "bibls=zoteroExport.findall('.//biblStruct', xmlns)\n",
    "for bibl in bibls:\n",
    "    id = bibl.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "    url = bibl.get(\"corresp\")\n",
    "    ids.append((id,url))\n",
    "\n",
    "ids.sort(key=lambda x: x[0])\n",
    "groups=[]\n",
    "for key, group in itertools.groupby(ids, lambda x: x[0]):\n",
    "    groups.append((key, [i[1] for i in list(group)]))\n",
    "\n",
    "for i in groups:\n",
    "    if len(i[1]) > 1:\n",
    "        print(i[0]+\": \"+str(len(i[1]))+\" entries with this id: \"+\", \".join(i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Zotero Export against TEI all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tei_all = \"../../803_RNG_Schematron/tei_all.rng\"\n",
    "errors=validate(pathToZoteroExport, tei_all)\n",
    "if not errors:\n",
    "    print(\"Zotero export is valid!\")\n",
    "else:\n",
    "    errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow but validating code\n",
    "\n",
    "The following code fetches items Zotero unique id by Zotero unique id. This is much slower but could potentially find missing items."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "errors = []\n",
    "max_fetch = limit_downloads_to if limit_downloads_to is not None else len(item_ids)\n",
    "logging.info(\"Fetching at most \" + str(max_fetch) + \" TEI/XML.\")\n",
    "async def get_item_tei_from_group(item_id, session):\n",
    "    bibl_struct = await get_item_tei(group_id, item_id, session)\n",
    "    if bibl_struct:\n",
    "        list_bibl.append(bibl_struct)\n",
    "    else:\n",
    "        logging.debug(\"Can not append \" + item_id)\n",
    "        errors.append(item_id)\n",
    "\n",
    "async def async_download(): \n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        await asyncio.gather(*[get_item_tei_from_group(item_id, session) for item_id in item_ids[:max_fetch]])\n",
    "\n",
    "asyncio.run(async_download())\n",
    "\n",
    "list_bibl[:] = sorted(list_bibl, key=lambda child: child.get(\"{http://www.w3.org/XML/1998/namespace}id\"))\n",
    "with open('../../010_manannot/vicav_biblio_tei_zotero.xml', 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8',xml_declaration=True)\n",
    "    logging.info(\"TEI export done.\")\n",
    "\n",
    "# Export IDs of items with errors\n",
    "with open(\"errors.json\",\"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(errors, f)\n",
    "    logging.info(\"Exported errors.json.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
