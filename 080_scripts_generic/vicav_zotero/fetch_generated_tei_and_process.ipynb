{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script to automate the export and manipulation of the VICAV-library\n",
    "\n",
    "## Import Package eTree to parse XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import asyncio\n",
    "import aiohttp\n",
    "# this module is needed to make asyncio.run work inside the notebook as well as in the generated python script\n",
    "import nest_asyncio\n",
    "from random import random\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define name-space for xml-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmlns = {\"tei\": \"http://www.tei-c.org/ns/1.0\", \"xml\":\"http://www.w3.org/XML/1998/namespace\", \"\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "for key in xmlns:\n",
    "    ET.register_namespace(key, xmlns[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access to the VICAV Zotero library\n",
    "\n",
    "* Use API_TOKEN from environment to access Zotero\n",
    "* Set the Zotero group id for VICAV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 17:30:15,402 - limit_downloads_to = None, conn_limit = 16, total_timeout = 3s\n"
     ]
    }
   ],
   "source": [
    "request_headers = {'Authorization': 'Bearer ' + os.environ['API_TOKEN']}\n",
    "group_id = \"2165756\"\n",
    "limit_downloads_to = int(os.environ['LIMIT_DOWNLOADS_TO']) if 'LIMIT_DOWNLOADS_TO' in os.environ and os.environ['LIMIT_DOWNLOADS_TO'] else None\n",
    "# On GitHub more than one connections to api.zotero.org was broken when this environment variable was introduced\n",
    "conn_limit=int(os.environ['MAX_CONNECTIONS']) if 'MAX_CONNECTIONS' in os.environ and os.environ['MAX_CONNECTIONS'] else 16 \n",
    "total_timeout=int(os.environ['TIMEOUT']) if 'TIMEOUT' in os.environ and os.environ['TIMEOUT'] else 3 #s\n",
    "logging.info(\"limit_downloads_to = \" + str(limit_downloads_to) + \", conn_limit = \" + str(conn_limit) + ', total_timeout = ' + str(total_timeout) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Read all items in the library\n",
    "\n",
    "Load items from Zotero group library\n",
    "\n",
    "    Args: \n",
    "        group_id (str): ID of a Zotero group\n",
    "        limit (int): number of items to retrieve from library, maximum is 100.\n",
    "        start (int): item number to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_items(session, group_id:str,limit:int,start:int,itemType = None,format = None):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + \"?limit=\" + str(limit) + \"&start=\" + str(start) + (\"&itemType=\"+itemType if itemType is not None else \"\") + (\"&format=\"+format if format is not None else \"\")\n",
    "    retries = 2\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            async with session.get(url=request_url, headers=request_headers) as response:\n",
    "                if response.status == 200:\n",
    "                    if format == \"tei\":\n",
    "                        parsed = ET.fromstring(await response.read())\n",
    "                    else:\n",
    "                        parsed = json.loads(await response.text())\n",
    "                    response_headers = response.headers\n",
    "                    logging.info(\"Got \"+request_url + (\" Backoff: \" + response.headers[\"Backoff\"] if \"Backoff\" in response.headers else \"\"))\n",
    "                    return parsed, response_headers\n",
    "        except Exception as e:\n",
    "            retries = retries - 1\n",
    "            await asyncio.sleep(3 + random() + 0.5)\n",
    "            logging.info(\"Retrying after \" + type(e).__name__ + (\": \" + str(e) if str(e) else \"\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "async def test1():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout) # 10 min\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test1, test_reponse_headers = await get_items(session, group_id,10,1000)\n",
    "        test1a, test_reponse_headersa = await get_items(session, group_id,10,300,\"note\")\n",
    "        print(test_reponse_headers, '\\n', test_reponse_headersa, '\\n', len(test1), ' ', len(test1a), '\\n', test1)\n",
    "asyncio.run(test1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get total number of items in group library\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group\n",
    "    \n",
    "    Returns:\n",
    "        int: number of items in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def total_number_items(group_id) -> int:\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return int(response.headers[\"Total-Results\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "test2 = total_number_items(group_id)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get headers of Zotero-Api-Calls\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_headers(group_id):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return response.headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "test3 = get_headers(group_id)\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get links from headers\n",
    "\n",
    "    Args:\n",
    "        headers: http-headers of a response\n",
    "\n",
    "    Returns:\n",
    "        dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links_from_headers(headers) -> dict:\n",
    "    link_list = headers[\"Link\"].split(\",\")\n",
    "    links = {}\n",
    "    for link_item in link_list:\n",
    "        #print(link_item)\n",
    "        link_type = link_item.split('; rel=\"')[1].replace('\"','').strip()\n",
    "        link_value = link_item.split('; rel=\"')[0].replace(\"<\",\"\").replace(\">\",\"\").strip()\n",
    "        links[link_type] = link_value\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "test_headers = get_headers(group_id)\n",
    "test4 = get_links_from_headers(test_headers)\n",
    "print(test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Get all items of a collection/group lib\n",
    "\n",
    "* Generate all links with `for start in range(limit,last,limit)`.\n",
    "* Then download in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def fetch(request_url, session, format = None):\n",
    "    await asyncio.sleep(1 * random() + 0.5)\n",
    "    retries = 2\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            async with session.get(request_url, headers=request_headers) as response:\n",
    "                if format == \"tei\":\n",
    "                    content = ET.fromstring(await response.read())\n",
    "                else:\n",
    "                    content = json.loads(await response.text())\n",
    "                logging.info(\"Got \"+request_url + (\" Backoff: \" + response.headers[\"Backoff\"] if \"Backoff\" in response.headers else \"\"))\n",
    "                return {\"status\": response.status, \"data\": content}\n",
    "        except Exception as e:\n",
    "            retries = retries - 1\n",
    "            await asyncio.sleep(3 + random() + 0.5)\n",
    "            logging.info(\"Retrying after \" + type(e).__name__ + (\": \" + str(e) if str(e) else \"\"))\n",
    "\n",
    "async def fetch_batch(url_list, format = None):\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        responses = await asyncio.gather(*[fetch(url, session, format) for url in url_list])\n",
    "    return responses\n",
    "\n",
    "async def get_all_items(session, group_id, itemType = None, format = None):\n",
    "    logging.info(\"Getting all items\" + \n",
    "                 ((\" of type \" + itemType) if itemType is not None else \"\") + \n",
    "                 ((\" formatted as \" + format) if format is not None else \"\") + \" now.\")\n",
    "\n",
    "    # settings to be used in the function to get the items (limit is max 100 per single request)\n",
    "    limit=100\n",
    "    start=0\n",
    "    urls = []\n",
    "    \n",
    "    # get the first 200 items to start with\n",
    "    first_round=await get_items(session, group_id,limit,start,itemType,format)\n",
    "    allitems = first_round[0]\n",
    "    \n",
    "    # get the next link from the headers\n",
    "    next_url = get_links_from_headers(first_round[1])[\"next\"]\n",
    "    last_url = get_links_from_headers(first_round[1])[\"last\"]\n",
    "    next_url_parsed = urlparse(next_url)\n",
    "    parsed_qs = parse_qs(next_url_parsed.query)\n",
    "    last_qs = parse_qs(urlparse(last_url).query)\n",
    "    last_start = limit_downloads_to if limit_downloads_to is not None and format is not None else int(last_qs[\"start\"][0])\n",
    "    for start in range(limit, last_start+1, limit):\n",
    "        parsed_qs[\"start\"] = [start]\n",
    "        parsed = next_url_parsed._replace(query=urlencode(parsed_qs, doseq=True))\n",
    "        urls.append(parsed.geturl())\n",
    "    i = 0\n",
    "    while len(urls[i:i+conn_limit]) > 0:\n",
    "        for response in await fetch_batch(urls[i:i+conn_limit], format):\n",
    "            if isinstance(allitems, ET.Element) and isinstance(response[\"data\"], ET.Element):\n",
    "                for child in response[\"data\"]:\n",
    "                    allitems.append(child)\n",
    "            else:\n",
    "                allitems = allitems + response[\"data\"]   \n",
    "        i = i + conn_limit\n",
    "    \n",
    "    return allitems"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "async def test5():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test5 = await get_all_items(session, group_id)\n",
    "        print(test5)\n",
    "asyncio.run(test5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all items of a group library in a json file\n",
    "\n",
    "    Args:\n",
    "        group_id (str): ID of a Zotero group\n",
    "        filename (str): name of the export file including file-extension\n",
    "\n",
    "    Returns:\n",
    "        bool: True if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_all_items_to_file(group_id,filename) ->bool: \n",
    "    allitems = get_all_items(group_id)\n",
    "    with open(filename,\"w\") as f:\n",
    "        json.dump(allitems, f)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#export_all_items_to_file(group_id,\"export_grouplib.json\")\n",
    "with open(\"export_grouplib.json\",\"w\") as f:\n",
    "    json.dump(test5, f)\n",
    "all_items = test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store export in a file and get all item ids\n",
    "\n",
    "The export contains also the note items. These are child items of some other item in this export. They have a parent reference.\n",
    "\n",
    "There are also attachment items. These are child items of some other item in this export. Most of them have a parent reference but some don't have a parent item (anymore?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 17:06:50,209 - Grouplib export json already exists. Delete to fetch again (time consuming).\n",
      "2023-07-22 17:06:51,431 - Exported json.\n"
     ]
    }
   ],
   "source": [
    "json_file = \"export_grouplib.json\"\n",
    "item_ids = []\n",
    "note_ids = []\n",
    "attachment_ids = []\n",
    "async def get_generic_items(session):\n",
    "    if os.path.isfile(json_file):\n",
    "        logging.info(\"Grouplib export json already exists. Delete to fetch again (time consuming).\")\n",
    "        with open(json_file, 'r') as f:\n",
    "            all_items = json.load(f)    \n",
    "    else:\n",
    "        all_items = await get_all_items(session, group_id)\n",
    "    return all_items\n",
    "\n",
    "async def get_export_json():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_generic_items(session)\n",
    "    # all_items = test5\n",
    "    with open(json_file,\"w\") as f:\n",
    "        json.dump(all_items, f)\n",
    "        logging.info(\"Exported json.\")\n",
    "    \n",
    "    for item in all_items:\n",
    "        item_id = item[\"key\"]\n",
    "        item_type = item[\"data\"][\"itemType\"]\n",
    "        if item_type == 'note':\n",
    "            note_ids.append(item_id)\n",
    "        elif item_type == 'attachment':\n",
    "            attachment_ids.append(item_id)\n",
    "        else:\n",
    "            item_ids.append(item_id)\n",
    "    return all_items\n",
    "all_items = asyncio.run(get_export_json())\n",
    "all_items_map = {data[\"key\"]:data for data in all_items}\n",
    "all_notes_map = {data[\"data\"][\"parentItem\"]:data for data in [all_items_map[id] for id in note_ids]}\n",
    "all_attachments_map = {data[\"data\"][\"parentItem\"] if \"parentItem\" in data[\"data\"] else \"ZZZZZZZZ\":data for data in [all_items_map[id] for id in attachment_ids]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "print(len(all_items), ' ', len(note_ids), ' ', len(item_ids), '\\n', item_ids[:10],\n",
    "      '\\nBibl items:\\n', dict(list(all_items_map.items())[:10]),\n",
    "      '\\nNote items:\\n', dict(list(all_notes_map.items())[:10]),\n",
    "      '\\nAttachement items:\\n', dict(list(all_attachments_map.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace xml:id with biblid from extra-field\n",
    "\n",
    "Most (but currently not all) Zotero items should have a canonical biblid assigned. This function gets the value from data/extra and \n",
    "tries to extract the canonical biblid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_biblid_from_extra(item):\n",
    "    if \"extra\" in item[\"data\"]:\n",
    "        if item[\"data\"][\"extra\"] != \"\":\n",
    "            if \"(biblid:\" in item[\"data\"][\"extra\"]:\n",
    "                return item[\"data\"][\"extra\"].split(\":\")[1].replace(\")\",\"\")\n",
    "            else: \n",
    "                return None\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "get_biblid_from_extra(all_items[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "for item in all_items[0:20]:\n",
    "    print(get_biblid_from_extra(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biblid_by_zuid={item[\"key\"]: get_biblid_from_extra(item)\n",
    "               for item in all_items}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "biblid_by_zuid[\"D25ZTU9X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the geo data and replace tags with geo refs\n",
    "\n",
    "geo data is in `../../vicav_biblio/vicav_geodata.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_data = ET.parse(\"../../010_manannot/vicav_geodata.xml\")\n",
    "geo_parent_map = {c:p for p in geo_data.iter( ) for c in p}\n",
    "place_by_name = {placeName.text: \n",
    "                 {\"type\": geo_parent_map[placeName].get(\"type\"),\n",
    "                  \"geo\": geo_parent_map[placeName].find(\"./tei:location/tei:geo[@decls='#dd']\",xmlns).text,\n",
    "                  \"el\": geo_parent_map[placeName]}\n",
    "                for placeName in geo_data.findall(\".//tei:listPlace/tei:place/tei:placeName\", xmlns)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#place_by_name = {}\n",
    "#p=1\n",
    "#for placeName in geo_data.findall(\".//tei:listPlace/tei:place/tei:placeName\", xmlns):\n",
    "#    p=p+1\n",
    "#    try:\n",
    "#        place_by_name = {**place_by_name, **{placeName.text: {\"type\": geo_parent_map[placeName].get(\"type\"),\n",
    "#                                                              \"geo\": geo_parent_map[placeName].find(\"./tei:location/tei:geo[@decls='#dd']\",xmlns).text,\n",
    "#                                                              \"el\": geo_parent_map[placeName]}}}\n",
    "#    except AttributeError:\n",
    "#        logging.info(\"Pos \"+str(p)+\" :\"+str(ET.tostring(geo_parent_map[placeName])))\n",
    "\n",
    "print(geo_data.find(\".//tei:listPlace\", xmlns)[1].attrib[\"{http://www.w3.org/XML/1998/namespace}id\"], '\\n',\n",
    "    dict(list(place_by_name.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the current mapping for xml:id to Zoteros unique ID\n",
    "\n",
    "Zotero suggests readable @xml:id but those are not unique between runs or  \n",
    "take into account that there may be more than one works by one author in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_zotero_unique_id = re.compile(r'https?://zotero.org/groups/[\\d]+/items/(?P<zuid>[A-Z0-9]+)')\n",
    "current_bibl_data = ET.parse(\"../../010_manannot/vicav_biblio_tei_zotero.xml\")\n",
    "xmlid_by_zuid = {get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "                 for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns)}\n",
    "zuid_by_xmlid = {bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\"): get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]\n",
    "                 for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns)}\n",
    "duplicate_xmlid = {}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "xmlid_by_zuid = {}\n",
    "for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns):\n",
    "    try:\n",
    "        xmlid_by_zuid = {**xmlid_by_zuid,\n",
    "                         **{get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\")}\n",
    "                        }\n",
    "    except AttributeError:\n",
    "        logging.info(ET.tostring(bibStr))\n",
    "m = get_zotero_unique_id.match(\"http://zotero.org/groups/2165756/items/5XHDCICS\")\n",
    "m.groupdict()\n",
    "xmlid_by_zuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Get all TEIs from Zotero\n",
    "\n",
    "man nimmt die Liste mit den IDs der entries, baut für jeden entry die URL nach dem Muster  \n",
    "https://api.zotero.org/groups/2165756/items/944KQVKQ?format=tei  \n",
    "man lädt das mit GET requesst  \n",
    "dann aus dem response den body und parsed das mit ET from string, nimmt daraus das  \n",
    "`<biblStruct>` Element;  \n",
    "baut eine gemeinsame `<listBibl>` und fügt das geparste Element ein,  \n",
    "dann dumpt man den ganzen Element-Tree\n",
    "\n",
    "### Retrieves TEI of an item generated by Zotero\n",
    "\n",
    "Resolves place names to geo coordinates using the place by name dict created above.\n",
    "\n",
    "### Keeping the xml:ids stable\n",
    "\n",
    "The code uses the Zotero unique ids to look up the @xml:id in the current bibliography and change it to that if it is needed.  \n",
    "Additionally if the id of the entry just downloaded does not match the known Zotero unique id a new unique @xml:id is generated appending b-z.  \n",
    "This code is not tested very much for corner cases. It should be replaced by getting the canonical biblid from the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "tag_parser = re.compile(r'(?P<geo_type>[^:]+):(?P<geo_name>[^[]+)(\\[(?P<long>[\\d.,]+) +(?P<lat>[\\d.,]+)])?')\n",
    "\n",
    "def create_geo_tag(tags_el, tag):\n",
    "    #starts with reg: geo: diaGroup: -> lookup, get geo location and create elemnt\n",
    "    # uses PEP 634, requires python 3.10+\n",
    "    m = tag_parser.match(tag)\n",
    "    if m is not None:\n",
    "        match m.groupdict():\n",
    "            case {\"geo_type\": \"reg\" | \"geo\" | \"diaGroup\", \"geo_name\": geo_name, \"long\": long, \"lat\": lat}:\n",
    "                tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "                geo_name = geo_name.rstrip()\n",
    "                ET.SubElement(tag_note_el, \"name\", type=m.groupdict()[\"geo_type\"]).text = geo_name\n",
    "                if geo_name in place_by_name:\n",
    "                    ET.SubElement(tag_note_el, \"geo\").text = place_by_name[geo_name][\"geo\"]\n",
    "                else:\n",
    "                    ET.SubElement(tag_note_el, \"note\", type=\"missing_geo_data\")\n",
    "                return tag_note_el\n",
    "    if tag in place_by_name:\n",
    "        tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\", subtype=\"unmarked_geo\")\n",
    "        ET.SubElement(tag_note_el, \"name\", type=place_by_name[tag][\"type\"]).text = tag\n",
    "        ET.SubElement(tag_note_el, \"geo\").text = place_by_name[tag][\"geo\"]\n",
    "        return tag_note_el\n",
    "    ret = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "    ret.text = tag\n",
    "    return ret\n",
    "\n",
    "def extend_item_tei(bibl):\n",
    "    try:\n",
    "        zuid = get_zotero_unique_id.match(bibl.get(\"corresp\")).groupdict()[\"zuid\"]\n",
    "        logging.debug(\"Zoterio unique ID: \" + zuid)\n",
    "        current_xmlid = bibl.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "        logging.debug(\"current @xml:id: \" + current_xmlid)\n",
    "        if zuid in xmlid_by_zuid and current_xmlid != xmlid_by_zuid[zuid]:\n",
    "            bibl.set(\"{http://www.w3.org/XML/1998/namespace}id\", xmlid_by_zuid[zuid])\n",
    "            logging.info(\"Changed @xml:id for item \" + zuid + \" from \"+ current_xmlid + \" to \" + xmlid_by_zuid[zuid] + \".\")\n",
    "        elif current_xmlid in zuid_by_xmlid and zuid_by_xmlid[current_xmlid] != zuid:\n",
    "            initial_xmlid = current_xmlid\n",
    "            if not current_xmlid in duplicate_xmlid:\n",
    "                duplicate_xmlid[current_xmlid] = current_xmlid + \"b\"\n",
    "            else:\n",
    "                duplicate_xmlid[current_xmlid] = duplicate_xmlid[current_xmlid][:-1] + chr(ord(duplicate_xmlid[current_xmlid][-1]) + 1)\n",
    "            current_xmlid = duplicate_xmlid[current_xmlid]\n",
    "            if current_xmlid in zuid_by_xmlid and zuid_by_xmlid[current_xmlid] != zuid:\n",
    "                logging.error(\"genereated @xml:id for item \" + zuid + \" is in use!\")\n",
    "            bibl.set(\"{http://www.w3.org/XML/1998/namespace}id\", current_xmlid)            \n",
    "            logging.info(\"Changed @xml:id for item \" + zuid + \" from \"+ initial_xmlid +\n",
    "                         \" to \" + current_xmlid + \" (duplicate of \" + zuid_by_xmlid[initial_xmlid] + \")\")\n",
    "        if zuid in all_notes_map:\n",
    "            note_for_zuid = all_notes_map[zuid][\"data\"][\"note\"].replace(\"&\", \"&amp;\")\n",
    "            parsed_note = ET.fromstring(\"<note>\"+note_for_zuid+\"</note>\")\n",
    "            bibl.append(parsed_note)\n",
    "        tags = all_items_map[zuid][\"data\"][\"tags\"]\n",
    "        if len(tags) > 0:\n",
    "            tags_el = ET.SubElement(bibl, \"note\", type=\"tags\")\n",
    "            for o in tags:\n",
    "                create_geo_tag(tags_el, o[\"tag\"])\n",
    "\n",
    "    except xml.etree.ElementTree.ParseError:\n",
    "        logging.info(\"XML parser error in notes for item id \"+zuid+\"\\n\"+note_for_zuid)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + zuid)\n",
    "    logging.debug(\"Extended TEI for \" + zuid)\n",
    "\n",
    "async def get_item_tei(group_id,item_id,session):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + item_id + \"?format=tei\"\n",
    "    bibl = None\n",
    "    note_for_item_id = \"\"\n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        async with session.get(url=request_url, headers=request_headers) as response:\n",
    "            response_text = await response.text()\n",
    "        list_bibl = ET.fromstring(response_text)\n",
    "        bibl = list_bibl.find(\"tei:biblStruct\",xmlns)\n",
    "        logging.debug(\"XML: \" + ET.tostring(bibl, encoding=\"unicode\"))\n",
    "        if bibl is None:\n",
    "            logging.info(\"There is no biblStruct in the response for item \" + item_id +\":\\n\"+response_text)\n",
    "            return bibl\n",
    "        extend_item_tei(bibl)\n",
    "    except asyncio.TimeoutError:\n",
    "        logging.info(\"Timeout fetching \" + item_id)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + item_id)\n",
    "    logging.info(\"Fetched TEI for \" + item_id)\n",
    "    return bibl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 17:06:52,722 - Fetched TEI for 944KQVKQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<biblStruct xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"journalArticle\" xml:id=\"Harahsheh2020\" corresp=\"http://zotero.org/groups/2165756/items/944KQVKQ\">\n",
      "  <analytic>\n",
      "    <title level=\"a\">Animal names used to address people in Jordanian spoken Arabic</title>\n",
      "    <author>\n",
      "      <forename>Ahmad Mohammad Ahmad al-</forename>\n",
      "      <surname>Harahsheh</surname>\n",
      "    </author>\n",
      "    <author>\n",
      "      <forename>Rafat M. al</forename>\n",
      "      <surname>Rousan</surname>\n",
      "    </author>\n",
      "  </analytic>\n",
      "  <monogr>\n",
      "    <title level=\"j\">Dirasat: Human and Social Sciences</title>\n",
      "    <idno type=\"ISSN\">10263721</idno>\n",
      "    <imprint>\n",
      "      <biblScope unit=\"volume\">47 i</biblScope>\n",
      "      <biblScope unit=\"page\">328-336</biblScope>\n",
      "      <date>2020</date>\n",
      "    </imprint>\n",
      "  </monogr>\n",
      "  <note>\n",
      "    <p>Accession Number: ICHA1094316. Harahsheh, Ahmad Mohammad Ahmad al-; Rousan, Rafat M. al. Issue Info: 47 i. Publication Date: 20200101. Number of Pages: 9. Document Type: Article. Language: English.</p>\n",
      "  </note>\n",
      "  <note type=\"tags\">\n",
      "    <note type=\"tag\">Animals (in Islamic arts, literatures, folklore, traditions, cultures, law)</note>\n",
      "    <note type=\"tag\">Anthropology &amp; ethnography</note>\n",
      "    <note type=\"tag\">Arabic language: colloquial</note>\n",
      "    <note type=\"tag\">Colloquial Arabic dialects Shami</note>\n",
      "    <note type=\"tag\" subtype=\"unmarked_geo\">\n",
      "      <name type=\"reg\">Jordan</name>\n",
      "      <geo>31.000000 36.000000</geo>\n",
      "    </note>\n",
      "    <note type=\"tag\">Jordan Social studies</note>\n",
      "  </note>\n",
      "</biblStruct>\n"
     ]
    }
   ],
   "source": [
    "async def get_item_tei_test():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        #test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "        #test = await get_item_tei(group_id,\"DXNCFAMR\",session)\n",
    "        #test = await get_item_tei(group_id,\"6QNLQCG9\",session)\n",
    "        test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "    ET.indent(test)\n",
    "    ET.dump(test)\n",
    "asyncio.run(get_item_tei_test())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(\"Notes:\\n\", all_notes_map[\"944KQVKQ\"][\"data\"][\"note\"], \"\\nTags:\\n\", all_items_map[\"944KQVKQ\"][\"data\"][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = ET.parse(\"listbibl_template.xml\")\n",
    "list_bibl = template.find(\"tei:text/tei:body/tei:listBibl\",xmlns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load template containing a listBibl-element that will be filled with the retrieved biblStruct elements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "ET.dump(list_bibl)\n",
    "list_bibl.append(test)\n",
    "ET.dump(list_bibl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the TEI\n",
    "\n",
    "* For each item-id get the TEI and append it to list-bibl\n",
    "* Save the resulting XML\n",
    "* Use the same method as for the JSON for the whole group lib\n",
    "* Then download in parallel.\n",
    "\n",
    "We need to consider https://www.zotero.org/support/dev/web_api/v3/basics#rate_limiting\n",
    "\n",
    "TODO: Maybe only get the all the top items in the group with https://api.zotero.org/groups/2165756/items/top?format=tei&limit=100&sort=creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 17:31:57,556 - Getting all items formatted as tei now.\n",
      "2023-07-22 17:31:59,752 - Got https://api.zotero.org/groups/2165756/items/?limit=100&start=0&format=tei\n",
      "2023-07-22 17:32:02,160 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=1400\n",
      "2023-07-22 17:32:02,249 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=100\n",
      "2023-07-22 17:32:02,600 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=1600\n",
      "2023-07-22 17:32:02,814 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=1000\n",
      "2023-07-22 17:32:02,894 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=1200\n",
      "2023-07-22 17:32:03,312 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=1100\n",
      "2023-07-22 17:32:03,881 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=600\n",
      "2023-07-22 17:32:04,024 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=1300\n",
      "2023-07-22 17:32:06,813 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,032 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,281 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,752 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,814 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,862 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,893 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:07,895 - Retrying after TimeoutError\n",
      "2023-07-22 17:32:08,525 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=200\n",
      "2023-07-22 17:32:08,747 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=500\n",
      "2023-07-22 17:32:08,933 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=400\n",
      "2023-07-22 17:32:09,071 - Got https://api.zotero.org/groups/2165756/items/?format=tei&limit=100&start=300\n"
     ]
    }
   ],
   "source": [
    "async def async_download():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_all_items(session, group_id, format = \"tei\")\n",
    "    return all_items\n",
    "\n",
    "all_items = asyncio.run(async_download())\n",
    "for bibl in all_items:\n",
    "    extend_item_tei(bibl)\n",
    "all_items[:] = sorted(all_items, key=lambda child: child.get(\"{http://www.w3.org/XML/1998/namespace}id\"))\n",
    "for item in all_items:\n",
    "    list_bibl.append(item)\n",
    "with open('../../010_manannot/vicav_biblio_tei_zotero.xml', 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8',xml_declaration=True)\n",
    "    logging.info(\"TEI export done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow but validating code\n",
    "\n",
    "The following code fetches items Zotero unique id by Zotero unique id. This is much slower but could potentially find missing items."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "custom",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "errors = []\n",
    "max_fetch = limit_downloads_to if limit_downloads_to is not None else len(item_ids)\n",
    "logging.info(\"Fetching at most \" + str(max_fetch) + \" TEI/XML.\")\n",
    "async def get_item_tei_from_group(item_id, session):\n",
    "    bibl_struct = await get_item_tei(group_id, item_id, session)\n",
    "    if bibl_struct:\n",
    "        list_bibl.append(bibl_struct)\n",
    "    else:\n",
    "        logging.debug(\"Can not append \" + item_id)\n",
    "        errors.append(item_id)\n",
    "\n",
    "async def async_download(): \n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        await asyncio.gather(*[get_item_tei_from_group(item_id, session) for item_id in item_ids[:max_fetch]])\n",
    "\n",
    "asyncio.run(async_download())\n",
    "\n",
    "list_bibl[:] = sorted(list_bibl, key=lambda child: child.get(\"{http://www.w3.org/XML/1998/namespace}id\"))\n",
    "with open('../../010_manannot/vicav_biblio_tei_zotero.xml', 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8',xml_declaration=True)\n",
    "    logging.info(\"TEI export done.\")\n",
    "\n",
    "# Export IDs of items with errors\n",
    "with open(\"errors.json\",\"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(errors, f)\n",
    "    logging.info(\"Exported errors.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
