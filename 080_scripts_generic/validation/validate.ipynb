{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fccc48a-93a3-408d-bd5d-509db359db17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WIBARAB FeatureDB Validation\n",
    "\n",
    "* Install & set up dependencies\n",
    "* extract schematron from RNG and transform to XSLT\n",
    "* run schematron-xslt on files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65d4064-25b5-403a-974f-e0dcfca6a1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import requests\n",
    "import pathlib\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import linecache as lc\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit\n",
    "import saxonche\n",
    "from zipfile import ZipFile\n",
    "from lxml import isoschematron, etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a8d77c-292e-4c1f-9d34-5d139f3fb585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaxonC-HE 12.3 from Saxonica\n",
      "/home/dschopper/data/WIBARAB/featuredb/080_scripts_generic\n"
     ]
    }
   ],
   "source": [
    "tmpDir = \"tmp\"\n",
    "libDir = \"lib\"\n",
    "os.makedirs(tmpDir, exist_ok=True)\n",
    "os.makedirs(libDir, exist_ok=True)\n",
    "nss = {\"tei\":\"http://www.tei-c.org/ns/1.0\", \"wib\":\"https://wibarab.acdh.oeaw.ac.at/langDesc\"}\n",
    "# the root of the git repository\n",
    "dataHome = \"../..\"\n",
    "\n",
    "# rng schema\n",
    "rngSchema = dataHome + \"/803_RNG_Schematron/featuredb.rng\"\n",
    "# the path to the annotated TEI transcription files\n",
    "manannot = dataHome + \"/010_manannot\"\n",
    "# the path to the feature documents \n",
    "features = manannot + \"/features\"\n",
    "\n",
    "# include those documents in validation which have the following status in //tei:revisionDesc/@status / ignore all others\n",
    "VALIDATE_DOCS_WITH_STATUS = \"done\"\n",
    "\n",
    "\n",
    "with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "# SaxonC 1.2.1 Python has many known bugs but isn't maintained anymore\n",
    "# Many of the documented API specs are not working\n",
    "    print(proc.version)\n",
    "    proc.set_cwd(os.path.dirname(os.path.abspath('')))\n",
    "    print(proc.cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8623f866-e5c8-4468-8c8c-52cd60c88b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downloadAndStore(url, force=False):   \n",
    "    #  filename of the file to be downloaded\n",
    "    fn = os.path.basename(url)\n",
    "    # fn w/o extension\n",
    "    basename = os.path.splitext(fn)[0]\n",
    "    # extension \n",
    "    ext = os.path.splitext(fn)[1]\n",
    "    dlFilePath = tmpDir + \"/\" + fn\n",
    "    if not os.path.exists(dlFilePath) and not force == True:\n",
    "        payload = requests.get(url).content\n",
    "        open(dlFilePath, 'wb').write(payload)\n",
    "    return dlFilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e38bceb-17e4-4cc3-8a92-e1ced01bcf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downloadAndUnzip(url):    \n",
    "    #  filename of the file to be downloaded\n",
    "    fn = os.path.basename(url)\n",
    "    # fn w/o extension\n",
    "    basename = os.path.splitext(fn)[0]\n",
    "    # extension \n",
    "    ext = os.path.splitext(fn)[1]\n",
    "    \n",
    "    if ext != \".zip\":\n",
    "        return \"not a zip archive\"\n",
    "    else:\n",
    "        zipFilePath = downloadAndStore(url)\n",
    "        # the path where the content should be extracted to\n",
    "        targetPath = libDir + \"/\" + basename\n",
    "        \n",
    "        \n",
    "        payload = requests.get(url).content\n",
    "        open(zipFilePath, 'wb').write(payload)\n",
    "        ZipFile(zipFilePath).extractall(path=targetPath)\n",
    "    \n",
    "    return targetPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5eed3-8026-447b-83b3-c8747acde3b4",
   "metadata": {},
   "source": [
    "### Install XSL based schematron validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc25b5b-f6c5-4427-b09f-ee6e892fa167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_schCompiler = None\n",
    "def setupSchXSLT():\n",
    "    global _schCompiler\n",
    "    if _schCompiler is not None:\n",
    "        return _schCompiler\n",
    "    schDLURL = \"https://github.com/schxslt/schxslt/releases/download/v1.9.5/schxslt-1.9.5-xslt-only.zip\"\n",
    "    schHome = downloadAndUnzip(schDLURL)\n",
    "    _schCompiler = schHome + \"/schxslt-1.9.5/2.0/pipeline-for-svrl.xsl\"\n",
    "    if os.path.exists(_schCompiler):\n",
    "        return _schCompiler\n",
    "    else: \n",
    "        print(\"error: something went wrong, cannot locate file '\" + schCompiler + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56289a0f-0f1c-472f-8dea-8deb36122a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lib/schxslt-1.9.5-xslt-only/schxslt-1.9.5/2.0/pipeline-for-svrl.xsl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setupSchXSLT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d065cfe-c23a-4774-b87d-8034f8171386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(s, xsl, o, parameters=[]):\n",
    "    # processor keeps files open on Windows and in doing so prevents moving or copying them\n",
    "    with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "        proc.set_configuration_property(\"xi\", \"on\")\n",
    "        saxon = proc.new_xslt30_processor()\n",
    "        for i in parameters:\n",
    "            saxon.set_parameter(name=i, value=proc.make_string_value(parameters[i]))\n",
    "        exec = saxon.compile_stylesheet(stylesheet_file=os.path.abspath(xsl))\n",
    "        exec.apply_templates_returning_file(source_file=os.path.abspath(s), output_file=os.path.abspath(o))\n",
    "        if exec.exception_occurred:\n",
    "            exec.get_error_message\n",
    "            #for i in range(saxon.exception_count()-1):\n",
    "            print(saxon.get_error_message())\n",
    "            print(os.path.abspath(s)+\" - \"+os.path.abspath(xsl)+\" -> \"+os.path.abspath(o)+\" failed\")\n",
    "        if os.path.exists(os.path.abspath(o)):\n",
    "            return o\n",
    "        else: \n",
    "            print(\"there was an error transforming \"+s+\" with stylesheet \"+xsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e873708a-9d7a-4af4-ac10-921f44a7296a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractSchematron(rng):\n",
    "    \"\"\"extracts a schematron document embedded in an rng schema\"\"\"\n",
    "    print(\"extracting Schematron document from \"+rng)\n",
    "    rng2sch = setupRNG2Sch()\n",
    "    sch = tmpDir + \"/\" + os.path.basename(rng) + \".sch\"\n",
    "    if not os.path.exists(sch):\n",
    "        transform(rng, rng2sch, sch)\n",
    "    return sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8368a4-e428-4805-85bc-9c10fc5e1b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compileSchematron(sch):\n",
    "    \"\"\"compiles a schematron document to an XSLT stylesheet\"\"\"\n",
    "    outputPath = tmpDir + \"/\" + os.path.basename(sch) + \".xsl\"\n",
    "    schCompiler = setupSchXSLT()\n",
    "    \n",
    "    transform(sch, schCompiler, outputPath)\n",
    "    if os.path.exists(outputPath):\n",
    "        return outputPath\n",
    "    else: \n",
    "        print(\"error: something went wrong, cannot locate file '\" + outputPath + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570110e1-e436-426f-a041-6951564b1a2e",
   "metadata": {},
   "source": [
    "## Prepare rng2sch styelsheet\n",
    "\n",
    "Returns path to the xsl that extracts schematron form the RelaxNG schema.\n",
    "This should only run once as the file gets locked (by saxon) and so further attempts to pring it to the correct location will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b825837-90fa-4323-b9f6-7b7c2bed5928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_rng2sch = None \n",
    "def setupRNG2Sch():\n",
    "    global _rng2sch\n",
    "    if _rng2sch is not None:\n",
    "        return _rng2sch\n",
    "    RNG2SchtrDL = \"https://raw.githubusercontent.com/Schematron/schematron/master/trunk/converters/code/ToSchematron/ExtractSchFromRNG.xsl\"\n",
    "    dltmp = downloadAndStore(RNG2SchtrDL)\n",
    "    # tweak XSLT \n",
    "    with open(dltmp, encoding='utf-8') as inputfile:\n",
    "        lines = inputfile.read()\n",
    "    lines = lines.replace( 'http://www.ascc.net/xml/schematron','http://purl.oclc.org/dsdl/schematron/')\n",
    "    lines = lines.replace( '<sch:schema','<sch:schema queryBinding=\"xslt2\"')\n",
    "    \n",
    "    with open(dltmp, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(lines)\n",
    "    _rng2sch = libDir+\"/\"+os.path.basename(dltmp)\n",
    "    os.replace(dltmp, _rng2sch)\n",
    "    if os.path.exists(_rng2sch):\n",
    "        return _rng2sch\n",
    "    else:\n",
    "        print(\"error: something went wrong, cannot locate file '\" + newPath + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edce6249-fa90-4c7b-b689-c1eae1f551ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lib/ExtractSchFromRNG.xsl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setupRNG2Sch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40a708e-4918-4ae1-96d2-43d6a7d8fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fvoByLinenumber(document, linenumber):\n",
    "    \"\"\"tries to identify the feature value observation at a given line number\"\"\"\n",
    "    pResp = re.compile('resp=[\\'\"](.+?)[\\'\"]')\n",
    "    pID = re.compile('xml:id=[\\'\"](.+?)[\\'\"]')\n",
    "    with open(document, \"r\", encoding='utf-8') as file:\n",
    "        fvos = []\n",
    "        index = 1\n",
    "        for line in file.readlines():\n",
    "            if \":featureValueObservation \" in line and \"resp\" in line:\n",
    "                fvos.append({'line':index, 'fvo':line, 'resp': pResp.search(line).group(1), 'id': pID.search(line).group(1)})\n",
    "            index += 1\n",
    "        file.close()\n",
    "    previousFvos = list(filter(lambda object: object['line'] < linenumber, fvos))\n",
    "    if len(previousFvos) == 0:\n",
    "        print(\"could not determine fvo for line \"+str(linenumber)+\" in document \"+document)\n",
    "    else:\n",
    "        return previousFvos[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e5e1179-7834-4ec4-ac91-76fa213b9f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def schValidate(sch, path):\n",
    "    \"\"\"validates a document (at path) against schematron schema (at sch)\"\"\"\n",
    "    errs = []\n",
    "    out = tmpDir + \"/validationReports/\" + os.path.basename(path)\n",
    "    xsl = compileSchematron(sch)\n",
    "    try:\n",
    "        transform(path, xsl, out)\n",
    "\n",
    "    except saxonche.PySaxonApiError as e:\n",
    "        # We swallow parsing errors here as they should have been reported by lxml already\n",
    "        print(\"an error occured while running schValidate on \"+path)\n",
    "        return []\n",
    "    \n",
    "    report = etree.parse(out)\n",
    "    successfulReport = report.findall(\"{http://purl.oclc.org/dsdl/svrl}successful-report\")\n",
    "    failedAssert = report.findall(\"{http://purl.oclc.org/dsdl/svrl}failed-assert\")\n",
    "    doc = etree.parse(path)\n",
    "    for s in successfulReport + failedAssert:\n",
    "        XPath = s.attrib['location'].replace('Q{http://www.tei-c.org/ns/1.0}','tei:').replace('Q{https://wibarab.acdh.oeaw.ac.at/langDesc}','wib:').replace('Q{}','')\n",
    "        # DEBUG\n",
    "        node = doc.xpath(XPath, namespaces=nss)[0]\n",
    "        if type(node) is etree._ElementUnicodeResult:\n",
    "            elt = node.getparent()\n",
    "        else:\n",
    "            elt = node\n",
    "        \n",
    "        fvo = elt.xpath(\"ancestor::wib:featureValueObservation\", namespaces=nss)[0]\n",
    "        fvoID = fvo.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "        fvoResp = fvo.get('resp')\n",
    "        \n",
    "        \n",
    "        msg = s.find(\"{http://purl.oclc.org/dsdl/svrl}text\").text        \n",
    "        errObj = {\n",
    "            \"type\" : \"error\",\n",
    "            \"message\":  msg,\n",
    "            \"line\" : fvo.sourceline,\n",
    "            \"source\": path,\n",
    "            \"location\": XPath,\n",
    "            \"stage\": \"schematron\",\n",
    "            \"exceptionType\": str(s.tag).replace(\"{http://purl.oclc.org/dsdl/svrl}\",\"\"),\n",
    "            \"fvoID\": fvoID,\n",
    "            \"fvoResp\": fvoResp\n",
    "        }\n",
    "        \n",
    "        errs.append(errObj)\n",
    "    return errs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57fbaca5-626e-4efa-bc68-c5b9a9db1b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(path, rngSchema):\n",
    "    \"\"\"Validate a document against the rngSchema. Returns a list of dicts of which each one represents a validation (or parsing) error.\"\"\"\n",
    "    validationErrors = []\n",
    "    sch = extractSchematron(rngSchema)\n",
    "    try:\n",
    "        doc = etree.parse(path)\n",
    "    \n",
    "        # relaxng validation\n",
    "        relaxng_doc = etree.parse(rngSchema)\n",
    "        relaxng = etree.RelaxNG(relaxng_doc)\n",
    "        relaxng.assertValid(doc)\n",
    "        \n",
    "        # schematron validation\n",
    "        schErrs = schValidate(sch, path)\n",
    "        if len(schErrs) >= 1:\n",
    "            validationErrors = validationErrors + schErrs\n",
    "    \n",
    "    except etree.XMLSyntaxError as e:\n",
    "        valErrObj = {\n",
    "            \"type\" : \"error\",\n",
    "            \"message\": str(e), \n",
    "            \"line\": e.lineno,\n",
    "            \"source\": path, \n",
    "            \"location\": \"n/a\",\n",
    "            \"stage\" : \"parsing\", \n",
    "            \"exceptionType\": type(e).__name__\n",
    "        }\n",
    "        fvoInfo = fvoByLinenumber(path, e.lineno)\n",
    "        if fvoInfo:\n",
    "            valErrObj[\"fvoID\"] = fvoInfo['id']\n",
    "            valErrObj[\"fvoResp\"] = fvoInfo['resp']\n",
    "        return valErrObj\n",
    "        \n",
    "    except etree.DocumentInvalid as e:\n",
    "        for error in e.error_log:\n",
    "            # we ignore rng errors about @schemaLocation since \n",
    "            # that is needed for validation in the TEI-enricher\n",
    "            if error.message != \"Invalid attribute schemaLocation for element TEI\":\n",
    "                location = \"n/a\" if error.path is None else error.path\n",
    "                valErrObj = {\n",
    "                    \"type\" : \"error\",\n",
    "                    \"message\": error.message, \n",
    "                    \"line\": error.line, \n",
    "                    \"source\": path, \n",
    "                    \"location\": location,\n",
    "                    \"stage\" : \"relaxng\", \n",
    "                    \"exceptionType\": type(e).__name__\n",
    "                }\n",
    "                # DEBUG\n",
    "                print(valErrObj)\n",
    "                fvoInfo = fvoByLinenumber(path, error.line)\n",
    "                if fvoInfo:\n",
    "                    valErrObj[\"fvoID\"] = fvoInfo['id']\n",
    "                    valErrObj[\"fvoResp\"] = fvoInfo['resp']\n",
    "                validationErrors.append(valErrObj)\n",
    "        \n",
    "        # if the document is invalid against the RNG, we still want to run schematron against it\n",
    "        schErrs = schValidate(sch, path)\n",
    "        if len(schErrs) >= 1:\n",
    "            validationErrors = validationErrors + schErrs\n",
    "        \n",
    "        \n",
    "    \n",
    "    return validationErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "290bcfce-aa20-4bd0-bb57-bcf37c3b8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docStatus(path):\n",
    "    \"\"\"returns the status of the document at path; if the document can't be parsed, it returns a dict with the error\"\"\"\n",
    "    try:\n",
    "        doc = etree.parse(path)\n",
    "        revisionDesc = doc.xpath(\"/tei:TEI/tei:teiHeader/tei:revisionDesc\", namespaces=nss)[0]\n",
    "        status = revisionDesc.attrib['status']\n",
    "        return status\n",
    "    # report documents which are not well-formed\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        valErrObj = {\n",
    "            \"type\" : \"error\",\n",
    "            \"message\": str(e), \n",
    "            \"line\": e.lineno,\n",
    "            \"source\": path, \n",
    "            \"location\": \"n/a\",\n",
    "            \"stage\" : \"parsing\", \n",
    "            \"exceptionType\": type(e).__name__\n",
    "        }\n",
    "        fvoInfo = fvoByLinenumber(path, e.lineno)\n",
    "        if fvoInfo:\n",
    "            valErrObj[\"fvoID\"] = fvoInfo['id']\n",
    "            valErrObj[\"fvoResp\"] = fvoInfo['resp']\n",
    "        return valErrObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb70d327-e12a-4c39-bc4f-c29722518595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validationErrors = []\n",
    "ignoredFiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21379b89-b400-470f-be6b-1a70f6fe324a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not determine fvo for line 84 in document ../../010_manannot/features/feature_bound_pronoun_2ps_pl_m.xml\n",
      "could not determine fvo for line 66 in document ../../010_manannot/features/feature_bound_pronoun_3ps_sg_m_after_vowel.xml\n",
      "could not determine fvo for line 79 in document ../../010_manannot/features/feature_IPFV_3sg_m_1w.xml\n",
      "could not determine fvo for line 84 in document ../../010_manannot/features/feature_bound_pronoun_3ps_sg_m_after_consonant.xml\n",
      "validating ../../010_manannot/features/features_q.xml\n",
      "extracting Schematron document from ../../803_RNG_Schematron/featuredb.rng\n",
      "{'type': 'error', 'message': 'Element bibl failed to validate attributes', 'line': 0, 'source': '../../010_manannot/features/features_q.xml', 'location': 'n/a', 'stage': 'relaxng', 'exceptionType': 'DocumentInvalid'}\n",
      "could not determine fvo for line 0 in document ../../010_manannot/features/features_q.xml\n",
      "{'type': 'error', 'message': 'Element body has extra content: div', 'line': 87, 'source': '../../010_manannot/features/features_q.xml', 'location': '/*/*[2]/*/*[2]', 'stage': 'relaxng', 'exceptionType': 'DocumentInvalid'}\n",
      "could not determine fvo for line 87 in document ../../010_manannot/features/features_q.xml\n",
      "0 found / 23 in total\n",
      "could not determine fvo for line 111 in document ../../010_manannot/features/feature_JAA_3sg_f.xml\n",
      "could not determine fvo for line 59 in document ../../010_manannot/features/feature_raising_a_pretonic_closed.xml\n",
      "could not determine fvo for line 60 in document ../../010_manannot/features/feature_bound_pronoun_1ps_pl.xml\n",
      "could not determine fvo for line 51 in document ../../010_manannot/features/feature_t_form_passive.xml\n",
      "could not determine fvo for line 75 in document ../../010_manannot/features/feature_bound_pronoun_1ps_sg_after_consonant.xml\n",
      "could not determine fvo for line 78 in document ../../010_manannot/features/feature_bound_pronoun_1ps_sg_after_vowel.xml\n"
     ]
    }
   ],
   "source": [
    "for i in os.scandir(features):\n",
    "    if i.name.endswith('.xml') and i.is_file():\n",
    "        filename = os.path.basename(i)\n",
    "        filepath = features + \"/\" + filename\n",
    "        status = docStatus(filepath)\n",
    "        \n",
    "        # if the document is not finished yet (//tei:revisionDesc/@status != DOCSTATUS_DONE), just ignore it\n",
    "        if type(status) is str and status != VALIDATE_DOCS_WITH_STATUS:\n",
    "            ignoredFiles.append({\n",
    "                \"source\" : filepath,\n",
    "                \"type\" : \"ignored\",\n",
    "                \"status\": status\n",
    "            })\n",
    "        # if the document couldn't be parsed, docStatus() returns a dict \n",
    "        # with some error information which is appended to the list of \n",
    "        # validation errors\n",
    "        elif type(status) is dict and status[\"type\"] == \"error\":\n",
    "            validationErrors.append(status) \n",
    "        \n",
    "        # … otherwise try to validate the document\n",
    "        else:\n",
    "            print(\"validating \" + filepath)\n",
    "            results = validate(filepath, rngSchema)\n",
    "            len(results)\n",
    "            if type(results) is list:\n",
    "                res_errs = filter(lambda x: x['type'] == \"error\", results)\n",
    "                res_ignored = filter(lambda x: x['type'] == \"ignored\", results)\n",
    "                validationErrors = validationErrors + list(res_errs)\n",
    "                print(f\"{len(list(res_errs))} found / {len(validationErrors)} in total\")\n",
    "            elif type(results) is dict:\n",
    "                if results['type'] == \"ignored\":\n",
    "                    ignoredFiles.append(results)\n",
    "            else:\n",
    "                print(\"unknown result type\")\n",
    "                print(results)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c956070f-37ce-4061-9074-7488260bddb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_clickable(source, line=None):\n",
    "    link = source.replace('../../','https://github.com/wibarab/featuredb/blob/main/')\n",
    "    if line:\n",
    "        return f'<a href=\"{link}#L{line}\">{source}</a>'\n",
    "    else:\n",
    "        return f'<a href=\"{link}\">{source}</a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1dfccf9-41f5-4643-9e1e-8ba22d261c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ignoredFiles) > 0:\n",
    "    df_ignored = pd.DataFrame(data=ignoredFiles).T\n",
    "    df_ignored = df_ignored.transpose()\n",
    "    df_ignored\n",
    "    ignoredReport = \"tmp/ignoredFiles.html\"\n",
    "    df_ignored['link'] = df_ignored.apply(lambda x: make_clickable(x['source']), axis=1)\n",
    "\n",
    "    with open(ignoredReport, 'w', encoding='utf-8') as f:\n",
    "        f.write(df_ignored.to_html(render_links=True, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1562f40-85ff-4936-b16a-4da69b3a8d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 44 validation errors\n"
     ]
    }
   ],
   "source": [
    "if len(validationErrors) > 0:\n",
    "    df_err = pd.DataFrame(data=validationErrors).T\n",
    "    df_err = df_err.transpose()\n",
    "    df_err \n",
    "    print(f\"found {len(validationErrors)} validation errors\")\n",
    "    errorReport = \"tmp/validationReport.html\"\n",
    "    df_err['link'] = df_err.apply(lambda x: make_clickable(x['source'], x['line']), axis=1)\n",
    "    with open(errorReport, 'w') as f:\n",
    "        f.write(df_err.to_html(render_links=True, escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
